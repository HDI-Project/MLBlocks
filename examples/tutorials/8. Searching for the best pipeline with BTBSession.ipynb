{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting and Tuning pipelines\n",
    "\n",
    "This guide shows you how to search for multiple pipelines for your problem\n",
    "and later on use a [BTBSession](https://hdi-project.github.io/BTB/api/btb.session.html#btb.session.BTBSession)\n",
    "to select and tune the best one.\n",
    "\n",
    "Note that some steps are not explained for simplicity. Full details\n",
    "about them can be found in the previous parts of the tutorial.\n",
    "\n",
    "Here we will:\n",
    "\n",
    "1. Load a dataset\n",
    "2. Search and load suitable templates\n",
    "3. Write a scoring function\n",
    "4. Build a BTBSession for our templates\n",
    "5. Run the session to find the best pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "The first step will be to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlprimitives.datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('census')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adult Census dataset.\n",
      "\n",
      "    Predict whether income exceeds $50K/yr based on census data. Also known as \"Adult\" dataset.\n",
      "\n",
      "    Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean\n",
      "    records was extracted using the following conditions: ((AAGE>16) && (AGI>100) &&\n",
      "    (AFNLWGT>1)&& (HRSWK>0))\n",
      "\n",
      "    Prediction task is to determine whether a person makes over 50K a year.\n",
      "\n",
      "    source: \"UCI\n",
      "    sourceURI: \"https://archive.ics.uci.edu/ml/datasets/census+income\"\n",
      "    \n",
      "Data Modality: single_table\n",
      "Task Type: classification\n",
      "Task Subtype: binary\n",
      "Data shape: (32561, 14)\n",
      "Target shape: (32561,)\n",
      "Metric: accuracy_score\n",
      "Extras: \n"
     ]
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and load suitable Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the `mlblocks.discovery.find_pipelines` function to search\n",
    "for compatible pipelines.\n",
    "\n",
    "In this case, we will be looking for `single_table/classification` pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['keras.Sequential.MLPBinaryClassifier',\n",
       " 'keras.Sequential.MLPMultiClassClassifier',\n",
       " 'single_table.classification',\n",
       " 'single_table.classification.text',\n",
       " 'single_table.classification.xgb',\n",
       " 'sklearn.decomposition.DictionaryLearning',\n",
       " 'sklearn.decomposition.FactorAnalysis',\n",
       " 'sklearn.decomposition.FastICA',\n",
       " 'sklearn.decomposition.KernelPCA',\n",
       " 'sklearn.decomposition.PCA',\n",
       " 'sklearn.decomposition.TruncatedSVD',\n",
       " 'sklearn.ensemble.AdaBoostClassifier',\n",
       " 'sklearn.ensemble.BaggingClassifier',\n",
       " 'sklearn.ensemble.ExtraTreesClassifier',\n",
       " 'sklearn.ensemble.GradientBoostingClassifier',\n",
       " 'sklearn.ensemble.IsolationForest',\n",
       " 'sklearn.ensemble.RandomForestClassifier',\n",
       " 'sklearn.ensemble.RandomTreesEmbedding',\n",
       " 'sklearn.linear_model.LogisticRegression']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlblocks.discovery import find_pipelines\n",
    "\n",
    "filters = {\n",
    "    'metadata.data_type': 'single_table',\n",
    "    'metadata.task_type': 'classification'\n",
    "}\n",
    "find_pipelines(filters=filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we will create a dictionary with MLPipeline instances that will be used as tempaltes for our tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlblocks import MLPipeline\n",
    "\n",
    "templates = [\n",
    "    'single_table.classification',\n",
    "    'single_table.classification.text',\n",
    "    'single_table.classification.xgb',\n",
    "    'sklearn.ensemble.AdaBoostClassifier',\n",
    "    'sklearn.ensemble.BaggingClassifier',\n",
    "    'sklearn.ensemble.ExtraTreesClassifier',\n",
    "    'sklearn.ensemble.GradientBoostingClassifier',\n",
    "]\n",
    "\n",
    "# limit number of estimators in XGB primitives to avoid long training times\n",
    "init_params = {\n",
    "    'xgboost.XGBClassifier#1': {\n",
    "        'n_estimators': 100\n",
    "    }\n",
    "}\n",
    "\n",
    "templates_dict = {\n",
    "    template: MLPipeline(template, init_params=init_params)\n",
    "    for template in templates\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlblocks.mlpipeline.MLPipeline at 0x7fb7caf2e470>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templates_dict['single_table.classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a scoring function\n",
    "\n",
    "In order to use a `BTBSession` we will need a function that is able to score a proposal,\n",
    "which will always be a pair of template name and proposed hyperparameters.\n",
    "\n",
    "In this case, the evaluation will be done using 5-fold cross validation over our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_validate(template_name, hyperparameters=None):\n",
    "    template = templates_dict[template_name]\n",
    "    scores = []\n",
    "    for X_train, X_test, y_train, y_test in dataset.get_splits(5):\n",
    "        pipeline = MLPipeline(template.to_dict())  # Make a copy of the template\n",
    "        if hyperparameters:\n",
    "            pipeline.set_hyperparameters(hyperparameters)\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        scores.append(dataset.score(y_test, y_pred))\n",
    "        \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the BTBSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create another dictionary with the tunable hyperparameters of each template.\n",
    "This will be used by the BTBSession to know how to tune each template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunables = {\n",
    "    name: template.get_tunable_hyperparameters(flat=True)\n",
    "    for name, template in templates_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "  'max_labels'): {'type': 'int', 'default': 0, 'range': [0, 100]},\n",
       " ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "  'lowercase'): {'type': 'bool', 'default': True},\n",
       " ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "  'binary'): {'type': 'bool', 'default': True},\n",
       " ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "  'max_features'): {'type': 'int', 'default': 1000, 'range': [1, 10000]},\n",
       " ('sklearn.impute.SimpleImputer#1', 'strategy'): {'type': 'str',\n",
       "  'default': 'mean',\n",
       "  'values': ['mean', 'median', 'most_frequent', 'constant']},\n",
       " ('xgboost.XGBClassifier#1', 'max_depth'): {'type': 'int',\n",
       "  'default': 3,\n",
       "  'range': [3, 10]},\n",
       " ('xgboost.XGBClassifier#1', 'learning_rate'): {'type': 'float',\n",
       "  'default': 0.1,\n",
       "  'range': [0, 1]},\n",
       " ('xgboost.XGBClassifier#1', 'gamma'): {'type': 'float',\n",
       "  'default': 0,\n",
       "  'range': [0, 1]},\n",
       " ('xgboost.XGBClassifier#1', 'min_child_weight'): {'type': 'int',\n",
       "  'default': 1,\n",
       "  'range': [1, 10]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunables['single_table.classification']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then create a `BTBSession` instance passing them and the `cross_validate` function.\n",
    "\n",
    "We will also be setting it in `verbose` mode, so we can have a better insight on what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.session import BTBSession\n",
    "\n",
    "session = BTBSession(tunables, cross_validate, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After everything is set up, we can start running the tuning session passing it\n",
    "the number of iterations that we want to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0caba0418d2649df8e867f10c6661017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-09 18:27:33,705 - INFO - session - Creating Tunable instance from dict.\n",
      "2020-06-09 18:27:33,706 - INFO - session - Obtaining default configuration for single_table.classification\n",
      "2020-06-09 18:27:39,855 - INFO - session - New optimal found: single_table.classification - 0.8639171383183359\n",
      "2020-06-09 18:27:39,860 - INFO - session - Creating Tunable instance from dict.\n",
      "2020-06-09 18:27:39,860 - INFO - session - Obtaining default configuration for single_table.classification.text\n",
      "2020-06-09 18:27:40,015 - ERROR - mlpipeline - Exception caught producing MLBlock mlprimitives.custom.text.TextCleaner#1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlpipeline.py\", line 635, in _produce_block\n",
      "    block_outputs = block.produce(**produce_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlblock.py\", line 320, in produce\n",
      "    return getattr(self.instance, self.produce_method)(**produce_kwargs)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/mlprimitives/custom/text.py\", line 113, in produce\n",
      "    texts = pd.Series(X)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/pandas/core/series.py\", line 264, in __init__\n",
      "    data = SingleBlockManager(data, index, fastpath=True)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1481, in __init__\n",
      "    block = make_block(block, placement=slice(0, len(axis)), ndim=1)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 3095, in make_block\n",
      "    return klass(values, ndim=ndim, placement=placement)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 2631, in __init__\n",
      "    placement=placement)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 87, in __init__\n",
      "    '{mgr}'.format(val=len(self.values), mgr=len(self.mgr_locs)))\n",
      "ValueError: Wrong number of items passed 14, placement implies 26048\n",
      "2020-06-09 18:27:40,019 - ERROR - session - Proposal 2 - single_table.classification.text crashed with the following configuration: ('mlprimitives.custom.text.TextCleaner#1', 'lower'): True\n",
      "('mlprimitives.custom.text.TextCleaner#1', 'accents'): True\n",
      "('mlprimitives.custom.text.TextCleaner#1', 'stopwords'): True\n",
      "('mlprimitives.custom.text.TextCleaner#1', 'non_alpha'): True\n",
      "('mlprimitives.custom.text.TextCleaner#1', 'single_chars'): True\n",
      "('mlprimitives.custom.feature_extraction.StringVectorizer#1', 'lowercase'): True\n",
      "('mlprimitives.custom.feature_extraction.StringVectorizer#1', 'binary'): True\n",
      "('mlprimitives.custom.feature_extraction.StringVectorizer#1', 'max_features'): 1000\n",
      "('sklearn.impute.SimpleImputer#1', 'strategy'): mean\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'n_estimators'): 10\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'criterion'): gini\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'max_features'): None\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'max_depth'): 1\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'min_samples_split'): 2\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'min_samples_leaf'): 1\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'min_weight_fraction_leaf'): 0.0\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'max_leaf_nodes'): 2\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'min_impurity_decrease'): 0.0\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'bootstrap'): True\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'oob_score'): False\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/btb/session.py\", line 336, in run\n",
      "    score = self._scorer(tunable_name, config)\n",
      "  File \"<ipython-input-6-067b925bbee5>\", line 11, in cross_validate\n",
      "    pipeline.fit(X_train, y_train)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlpipeline.py\", line 722, in fit\n",
      "    self._produce_block(block, block_name, context, output_variables, outputs)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlpipeline.py\", line 635, in _produce_block\n",
      "    block_outputs = block.produce(**produce_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlblock.py\", line 320, in produce\n",
      "    return getattr(self.instance, self.produce_method)(**produce_kwargs)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/mlprimitives/custom/text.py\", line 113, in produce\n",
      "    texts = pd.Series(X)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/pandas/core/series.py\", line 264, in __init__\n",
      "    data = SingleBlockManager(data, index, fastpath=True)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1481, in __init__\n",
      "    block = make_block(block, placement=slice(0, len(axis)), ndim=1)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 3095, in make_block\n",
      "    return klass(values, ndim=ndim, placement=placement)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 2631, in __init__\n",
      "    placement=placement)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 87, in __init__\n",
      "    '{mgr}'.format(val=len(self.values), mgr=len(self.mgr_locs)))\n",
      "ValueError: Wrong number of items passed 14, placement implies 26048\n",
      "2020-06-09 18:27:40,021 - WARNING - session - Too many errors: 1. Removing tunable single_table.classification.text\n",
      "2020-06-09 18:27:40,022 - INFO - session - Creating Tunable instance from dict.\n",
      "2020-06-09 18:27:40,023 - INFO - session - Obtaining default configuration for single_table.classification.xgb\n",
      "2020-06-09 18:27:45,404 - INFO - session - Creating Tunable instance from dict.\n",
      "2020-06-09 18:27:45,404 - INFO - session - Obtaining default configuration for sklearn.ensemble.AdaBoostClassifier\n",
      "2020-06-09 18:27:45,476 - ERROR - mlpipeline - Exception caught fitting MLBlock sklearn.ensemble.AdaBoostClassifier#1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlpipeline.py\", line 619, in _fit_block\n",
      "    block.fit(**fit_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlblock.py\", line 300, in fit\n",
      "    getattr(self.instance, self.fit_method)(**fit_kwargs)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\", line 412, in fit\n",
      "    return super(AdaBoostClassifier, self).fit(X, y, sample_weight)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\", line 110, in fit\n",
      "    y_numeric=is_regressor(self))\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 756, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 527, in check_array\n",
      "    array = np.asarray(array, dtype=dtype, order=order)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/numpy/core/numeric.py\", line 538, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: ' State-gov'\n",
      "2020-06-09 18:27:45,479 - ERROR - session - Proposal 4 - sklearn.ensemble.AdaBoostClassifier crashed with the following configuration: ('sklearn.ensemble.AdaBoostClassifier#1', 'n_estimators'): 50\n",
      "('sklearn.ensemble.AdaBoostClassifier#1', 'learning_rate'): 1.0\n",
      "('sklearn.ensemble.AdaBoostClassifier#1', 'algorithm'): SAMME.R\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/btb/session.py\", line 336, in run\n",
      "    score = self._scorer(tunable_name, config)\n",
      "  File \"<ipython-input-6-067b925bbee5>\", line 11, in cross_validate\n",
      "    pipeline.fit(X_train, y_train)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlpipeline.py\", line 719, in fit\n",
      "    self._fit_block(block, block_name, context)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlpipeline.py\", line 619, in _fit_block\n",
      "    block.fit(**fit_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlblock.py\", line 300, in fit\n",
      "    getattr(self.instance, self.fit_method)(**fit_kwargs)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\", line 412, in fit\n",
      "    return super(AdaBoostClassifier, self).fit(X, y, sample_weight)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py\", line 110, in fit\n",
      "    y_numeric=is_regressor(self))\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 756, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 527, in check_array\n",
      "    array = np.asarray(array, dtype=dtype, order=order)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/numpy/core/numeric.py\", line 538, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: ' State-gov'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-09 18:27:45,480 - WARNING - session - Too many errors: 1. Removing tunable sklearn.ensemble.AdaBoostClassifier\n",
      "2020-06-09 18:27:45,480 - INFO - session - Creating Tunable instance from dict.\n",
      "2020-06-09 18:27:45,480 - INFO - session - Obtaining default configuration for sklearn.ensemble.BaggingClassifier\n",
      "2020-06-09 18:27:45,565 - ERROR - mlpipeline - Exception caught fitting MLBlock sklearn.ensemble.BaggingClassifier#1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlpipeline.py\", line 619, in _fit_block\n",
      "    block.fit(**fit_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlblock.py\", line 300, in fit\n",
      "    getattr(self.instance, self.fit_method)(**fit_kwargs)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\", line 244, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\", line 378, in _fit\n",
      "    for i in range(n_jobs))\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\", line 111, in _parallel_build_estimators\n",
      "    estimator.fit(X[:, features], y, sample_weight=curr_sample_weight)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/tree/tree.py\", line 801, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/tree/tree.py\", line 116, in fit\n",
      "    X = check_array(X, dtype=DTYPE, accept_sparse=\"csc\")\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 527, in check_array\n",
      "    array = np.asarray(array, dtype=dtype, order=order)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/numpy/core/numeric.py\", line 538, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: ' Bachelors'\n",
      "2020-06-09 18:27:45,568 - ERROR - session - Proposal 5 - sklearn.ensemble.BaggingClassifier crashed with the following configuration: ('sklearn.ensemble.BaggingClassifier#1', 'n_estimators'): 50\n",
      "('sklearn.ensemble.BaggingClassifier#1', 'max_samples'): 1.0\n",
      "('sklearn.ensemble.BaggingClassifier#1', 'max_features'): 1\n",
      "('sklearn.ensemble.BaggingClassifier#1', 'bootstrap'): True\n",
      "('sklearn.ensemble.BaggingClassifier#1', 'bootstrap_features'): False\n",
      "('sklearn.ensemble.BaggingClassifier#1', 'oob_score'): False\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/btb/session.py\", line 336, in run\n",
      "    score = self._scorer(tunable_name, config)\n",
      "  File \"<ipython-input-6-067b925bbee5>\", line 11, in cross_validate\n",
      "    pipeline.fit(X_train, y_train)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlpipeline.py\", line 719, in fit\n",
      "    self._fit_block(block, block_name, context)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlpipeline.py\", line 619, in _fit_block\n",
      "    block.fit(**fit_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlblock.py\", line 300, in fit\n",
      "    getattr(self.instance, self.fit_method)(**fit_kwargs)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\", line 244, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\", line 378, in _fit\n",
      "    for i in range(n_jobs))\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 921, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 182, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 549, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 225, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\", line 111, in _parallel_build_estimators\n",
      "    estimator.fit(X[:, features], y, sample_weight=curr_sample_weight)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/tree/tree.py\", line 801, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/tree/tree.py\", line 116, in fit\n",
      "    X = check_array(X, dtype=DTYPE, accept_sparse=\"csc\")\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 527, in check_array\n",
      "    array = np.asarray(array, dtype=dtype, order=order)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/numpy/core/numeric.py\", line 538, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: ' Bachelors'\n",
      "2020-06-09 18:27:45,569 - WARNING - session - Too many errors: 1. Removing tunable sklearn.ensemble.BaggingClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'ef66788edb4fa1b7d8403e92bf328a1d',\n",
       " 'name': 'single_table.classification',\n",
       " 'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "   'max_labels'): 0,\n",
       "  ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "   'lowercase'): True,\n",
       "  ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "   'binary'): True,\n",
       "  ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "   'max_features'): 1000,\n",
       "  ('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "  ('xgboost.XGBClassifier#1', 'max_depth'): 3,\n",
       "  ('xgboost.XGBClassifier#1', 'learning_rate'): 0.1,\n",
       "  ('xgboost.XGBClassifier#1', 'gamma'): 0.0,\n",
       "  ('xgboost.XGBClassifier#1', 'min_child_weight'): 1},\n",
       " 'score': 0.8639171383183359}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this loop, the BTBSession will build pipelines based on our templates and evaluate them\n",
    "using our scoring function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate results\n",
    "\n",
    "When the session funishes running it will return a the best proposal available and the\n",
    "obtained score.\n",
    "\n",
    "These results are also available as the `best_proposal` attribute from the btb session object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ef66788edb4fa1b7d8403e92bf328a1d',\n",
       " 'name': 'single_table.classification',\n",
       " 'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "   'max_labels'): 0,\n",
       "  ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "   'lowercase'): True,\n",
       "  ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "   'binary'): True,\n",
       "  ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "   'max_features'): 1000,\n",
       "  ('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "  ('xgboost.XGBClassifier#1', 'max_depth'): 3,\n",
       "  ('xgboost.XGBClassifier#1', 'learning_rate'): 0.1,\n",
       "  ('xgboost.XGBClassifier#1', 'gamma'): 0.0,\n",
       "  ('xgboost.XGBClassifier#1', 'min_child_weight'): 1},\n",
       " 'score': 0.8639171383183359}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.best_proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we feel that the score can still be improved and want to keep searching, we can simply run the session again which will continue tuning over the previous results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f0e7ade60c485a9e74462e915317bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-09 18:27:45,624 - INFO - session - Creating Tunable instance from dict.\n",
      "2020-06-09 18:27:45,625 - INFO - session - Obtaining default configuration for sklearn.ensemble.ExtraTreesClassifier\n",
      "2020-06-09 18:27:45,695 - ERROR - mlpipeline - Exception caught fitting MLBlock sklearn.ensemble.ExtraTreesClassifier#1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlpipeline.py\", line 619, in _fit_block\n",
      "    block.fit(**fit_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlblock.py\", line 300, in fit\n",
      "    getattr(self.instance, self.fit_method)(**fit_kwargs)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/ensemble/forest.py\", line 250, in fit\n",
      "    X = check_array(X, accept_sparse=\"csc\", dtype=DTYPE)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 527, in check_array\n",
      "    array = np.asarray(array, dtype=dtype, order=order)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/numpy/core/numeric.py\", line 538, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: ' State-gov'\n",
      "2020-06-09 18:27:45,697 - ERROR - session - Proposal 6 - sklearn.ensemble.ExtraTreesClassifier crashed with the following configuration: ('sklearn.ensemble.ExtraTreesClassifier#1', 'n_estimators'): 10\n",
      "('sklearn.ensemble.ExtraTreesClassifier#1', 'criterion'): gini\n",
      "('sklearn.ensemble.ExtraTreesClassifier#1', 'max_features'): None\n",
      "('sklearn.ensemble.ExtraTreesClassifier#1', 'max_depth'): 1\n",
      "('sklearn.ensemble.ExtraTreesClassifier#1', 'min_samples_split'): 2\n",
      "('sklearn.ensemble.ExtraTreesClassifier#1', 'min_samples_leaf'): 1\n",
      "('sklearn.ensemble.ExtraTreesClassifier#1', 'min_weight_fraction_leaf'): 0.0\n",
      "('sklearn.ensemble.ExtraTreesClassifier#1', 'max_leaf_nodes'): 2\n",
      "('sklearn.ensemble.ExtraTreesClassifier#1', 'min_impurity_decrease'): 0.0\n",
      "('sklearn.ensemble.ExtraTreesClassifier#1', 'bootstrap'): False\n",
      "('sklearn.ensemble.ExtraTreesClassifier#1', 'oob_score'): False\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/btb/session.py\", line 336, in run\n",
      "    score = self._scorer(tunable_name, config)\n",
      "  File \"<ipython-input-6-067b925bbee5>\", line 11, in cross_validate\n",
      "    pipeline.fit(X_train, y_train)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlpipeline.py\", line 719, in fit\n",
      "    self._fit_block(block, block_name, context)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlpipeline.py\", line 619, in _fit_block\n",
      "    block.fit(**fit_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlblock.py\", line 300, in fit\n",
      "    getattr(self.instance, self.fit_method)(**fit_kwargs)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/ensemble/forest.py\", line 250, in fit\n",
      "    X = check_array(X, accept_sparse=\"csc\", dtype=DTYPE)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 527, in check_array\n",
      "    array = np.asarray(array, dtype=dtype, order=order)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/numpy/core/numeric.py\", line 538, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: ' State-gov'\n",
      "2020-06-09 18:27:45,698 - WARNING - session - Too many errors: 1. Removing tunable sklearn.ensemble.ExtraTreesClassifier\n",
      "2020-06-09 18:27:45,699 - INFO - session - Creating Tunable instance from dict.\n",
      "2020-06-09 18:27:45,699 - INFO - session - Obtaining default configuration for sklearn.ensemble.GradientBoostingClassifier\n",
      "2020-06-09 18:27:45,768 - ERROR - mlpipeline - Exception caught fitting MLBlock sklearn.ensemble.GradientBoostingClassifier#1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlpipeline.py\", line 619, in _fit_block\n",
      "    block.fit(**fit_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlblock.py\", line 300, in fit\n",
      "    getattr(self.instance, self.fit_method)(**fit_kwargs)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1395, in fit\n",
      "    X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'], dtype=DTYPE)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 756, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 527, in check_array\n",
      "    array = np.asarray(array, dtype=dtype, order=order)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/numpy/core/numeric.py\", line 538, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: ' State-gov'\n",
      "2020-06-09 18:27:45,770 - ERROR - session - Proposal 7 - sklearn.ensemble.GradientBoostingClassifier crashed with the following configuration: ('sklearn.ensemble.GradientBoostingClassifier#1', 'loss'): deviance\n",
      "('sklearn.ensemble.GradientBoostingClassifier#1', 'learning_rate'): 0.1\n",
      "('sklearn.ensemble.GradientBoostingClassifier#1', 'n_estimators'): 10\n",
      "('sklearn.ensemble.GradientBoostingClassifier#1', 'max_depth'): 3\n",
      "('sklearn.ensemble.GradientBoostingClassifier#1', 'criterion'): friedman_mse\n",
      "('sklearn.ensemble.GradientBoostingClassifier#1', 'min_samples_split'): 2\n",
      "('sklearn.ensemble.GradientBoostingClassifier#1', 'min_samples_leaf'): 1\n",
      "('sklearn.ensemble.GradientBoostingClassifier#1', 'min_weight_fraction_leaf'): 0.0\n",
      "('sklearn.ensemble.GradientBoostingClassifier#1', 'subsample'): 1.0\n",
      "('sklearn.ensemble.GradientBoostingClassifier#1', 'max_features'): None\n",
      "('sklearn.ensemble.GradientBoostingClassifier#1', 'max_leaf_nodes'): 2\n",
      "('sklearn.ensemble.GradientBoostingClassifier#1', 'min_impurity_decrease'): 0.0\n",
      "('sklearn.ensemble.GradientBoostingClassifier#1', 'validation_fraction'): 0.1\n",
      "('sklearn.ensemble.GradientBoostingClassifier#1', 'n_iter_no_change'): 1\n",
      "('sklearn.ensemble.GradientBoostingClassifier#1', 'tol'): 0.0001\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/btb/session.py\", line 336, in run\n",
      "    score = self._scorer(tunable_name, config)\n",
      "  File \"<ipython-input-6-067b925bbee5>\", line 11, in cross_validate\n",
      "    pipeline.fit(X_train, y_train)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlpipeline.py\", line 719, in fit\n",
      "    self._fit_block(block, block_name, context)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlpipeline.py\", line 619, in _fit_block\n",
      "    block.fit(**fit_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks.clean/mlblocks/mlblock.py\", line 300, in fit\n",
      "    getattr(self.instance, self.fit_method)(**fit_kwargs)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1395, in fit\n",
      "    X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'], dtype=DTYPE)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 756, in check_X_y\n",
      "    estimator=estimator)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 527, in check_array\n",
      "    array = np.asarray(array, dtype=dtype, order=order)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks.clean/lib/python3.6/site-packages/numpy/core/numeric.py\", line 538, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not convert string to float: ' State-gov'\n",
      "2020-06-09 18:27:45,771 - WARNING - session - Too many errors: 1. Removing tunable sklearn.ensemble.GradientBoostingClassifier\n",
      "2020-06-09 18:27:45,772 - INFO - session - Generating new proposal configuration for single_table.classification.xgb\n",
      "2020-06-09 18:27:54,940 - INFO - session - Generating new proposal configuration for single_table.classification\n",
      "2020-06-09 18:28:11,035 - INFO - session - Generating new proposal configuration for single_table.classification.xgb\n",
      "2020-06-09 18:28:16,082 - INFO - session - New optimal found: single_table.classification.xgb - 0.8725777466046928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-09 18:28:16,093 - INFO - session - Generating new proposal configuration for single_table.classification\n",
      "2020-06-09 18:28:22,502 - INFO - session - Generating new proposal configuration for single_table.classification.xgb\n",
      "2020-06-09 18:28:33,460 - INFO - session - Generating new proposal configuration for single_table.classification\n",
      "2020-06-09 18:28:41,217 - INFO - session - Generating new proposal configuration for single_table.classification\n",
      "2020-06-09 18:28:47,272 - INFO - session - Generating new proposal configuration for single_table.classification.xgb\n",
      "2020-06-09 18:28:54,772 - INFO - session - Generating new proposal configuration for single_table.classification\n",
      "2020-06-09 18:29:09,485 - INFO - session - Generating new proposal configuration for single_table.classification.xgb\n",
      "2020-06-09 18:29:15,094 - INFO - session - Generating new proposal configuration for single_table.classification\n",
      "2020-06-09 18:29:22,733 - INFO - session - Generating new proposal configuration for single_table.classification.xgb\n",
      "2020-06-09 18:29:28,379 - INFO - session - Generating new proposal configuration for single_table.classification\n",
      "2020-06-09 18:29:37,905 - INFO - session - Generating new proposal configuration for single_table.classification.xgb\n",
      "2020-06-09 18:29:52,996 - INFO - session - Generating new proposal configuration for single_table.classification\n",
      "2020-06-09 18:30:02,308 - INFO - session - Generating new proposal configuration for single_table.classification.xgb\n",
      "2020-06-09 18:30:10,888 - INFO - session - Generating new proposal configuration for single_table.classification\n",
      "2020-06-09 18:30:16,141 - INFO - session - Generating new proposal configuration for single_table.classification.xgb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '742456ff8b6f5aa926bbefb9fab42063',\n",
       " 'name': 'single_table.classification.xgb',\n",
       " 'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "   'max_labels'): 11,\n",
       "  ('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "  ('xgboost.XGBClassifier#1', 'max_depth'): 3,\n",
       "  ('xgboost.XGBClassifier#1', 'learning_rate'): 0.3695052906894838,\n",
       "  ('xgboost.XGBClassifier#1', 'gamma'): 0.006904783754312138,\n",
       "  ('xgboost.XGBClassifier#1', 'min_child_weight'): 1},\n",
       " 'score': 0.8725777466046928}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: If you look at the logs you will notice how the BTBSession captures the errors that finds\n",
    "while executing the pipelines and automatically discards the failing tempaltes to be able to continue\n",
    "the tuning session without wasting time on them.\n",
    "\n",
    "The number of errors that we want to wait before discarding a template can be changed passing the\n",
    "`max_errors` argument to the `BTBSession` when it is build.\n",
    "\n",
    "Isn't it cool?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the best pipeline\n",
    "\n",
    "Once we are satisfied with the results, we can then build an instance of the best pipeline\n",
    "by reading the `best_proposal` attribute from the `session`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '742456ff8b6f5aa926bbefb9fab42063',\n",
       " 'name': 'single_table.classification.xgb',\n",
       " 'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "   'max_labels'): 11,\n",
       "  ('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "  ('xgboost.XGBClassifier#1', 'max_depth'): 3,\n",
       "  ('xgboost.XGBClassifier#1', 'learning_rate'): 0.3695052906894838,\n",
       "  ('xgboost.XGBClassifier#1', 'gamma'): 0.006904783754312138,\n",
       "  ('xgboost.XGBClassifier#1', 'min_child_weight'): 1},\n",
       " 'score': 0.8725777466046928}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_proposal = session.best_proposal\n",
    "best_proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = templates_dict[best_proposal['name']]\n",
    "\n",
    "pipeline = MLPipeline(template.to_dict())\n",
    "pipeline.set_hyperparameters(best_proposal['config'])\n",
    "\n",
    "pipeline.fit(dataset.data, dataset.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore other results\n",
    "\n",
    "Optionally, if we are interested in exploring the results of the previous proposals we can access them\n",
    "in the `trials` attribute of the `session` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'ef66788edb4fa1b7d8403e92bf328a1d',\n",
       "  'name': 'single_table.classification',\n",
       "  'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "    'max_labels'): 0,\n",
       "   ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "    'lowercase'): True,\n",
       "   ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "    'binary'): True,\n",
       "   ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "    'max_features'): 1000,\n",
       "   ('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "   ('xgboost.XGBClassifier#1', 'max_depth'): 3,\n",
       "   ('xgboost.XGBClassifier#1', 'learning_rate'): 0.1,\n",
       "   ('xgboost.XGBClassifier#1', 'gamma'): 0.0,\n",
       "   ('xgboost.XGBClassifier#1', 'min_child_weight'): 1},\n",
       "  'score': 0.8639171383183359},\n",
       " {'id': 'adbd189a819483ddc869ceb94513b369',\n",
       "  'name': 'single_table.classification.text',\n",
       "  'config': {('mlprimitives.custom.text.TextCleaner#1', 'lower'): True,\n",
       "   ('mlprimitives.custom.text.TextCleaner#1', 'accents'): True,\n",
       "   ('mlprimitives.custom.text.TextCleaner#1', 'stopwords'): True,\n",
       "   ('mlprimitives.custom.text.TextCleaner#1', 'non_alpha'): True,\n",
       "   ('mlprimitives.custom.text.TextCleaner#1', 'single_chars'): True,\n",
       "   ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "    'lowercase'): True,\n",
       "   ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "    'binary'): True,\n",
       "   ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "    'max_features'): 1000,\n",
       "   ('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'n_estimators'): 10,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'criterion'): 'gini',\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'max_features'): None,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'max_depth'): 1,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'min_samples_split'): 2,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'min_samples_leaf'): 1,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1',\n",
       "    'min_weight_fraction_leaf'): 0.0,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'max_leaf_nodes'): 2,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'min_impurity_decrease'): 0.0,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'bootstrap'): True,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'oob_score'): False},\n",
       "  'score': None}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(session.proposals.values())[0:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
